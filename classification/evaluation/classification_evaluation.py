"""
Created on Sun Dec 17 21:27:20 2017

@author: Aleksa KociÄ‡

Contains methods for evaluating classification results.
"""

from sklearn import metrics
import numpy as np

def evaluate(true_labels, predicted_labels):
    """
    Evaluate the results of classification.
    
    Args:
        true_labels (list of str): List of labels of test set
        predicted_labels (list of str): List of labels generated by classifier
    
    Returns:
        (tuple of floats): Accuracy, Precision, Recall and F1 measure respectively
    """
    accuracy = np.round(metrics.accuracy_score(true_labels, predicted_labels), 
                        2)
    precision = np.round(metrics.precision_score(true_labels, predicted_labels, 
                                                 average='weighted'), 2)
    recall = np.round(metrics.recall_score(true_labels, predicted_labels,
                                           average='weighted'), 2)
    f1 = np.round(metrics.f1_score(true_labels, predicted_labels, 
                                   average='weighted'), 2)
    
    return accuracy, precision, recall, f1
    
def evaluate_print(true_labels, predicted_labels):
    """
    Print the results of classification.
    
    Args:
        true_labels (list of str): List of labels of test set
        predicted_labels (list of str): List of labels generated by classifier
    """
    accuracy, precision, recall, f1 = evaluate(true_labels, predicted_labels)
    
    print('Accuracy:', accuracy)
    print('Precision:', precision)
    print('Recall:', recall)
    print('F1:', f1)